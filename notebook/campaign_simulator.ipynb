{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_df = pd.read_csv(\"../data/campaigns.csv\").rename(columns={\"id\": \"campaign_id\"})\n",
    "event_df = pd.read_csv(\"../data/events.csv\")\n",
    "order_df = pd.read_csv(\"../data/orders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_df[\"to_date\"] = pd.to_datetime(campaign_df[\"to_date\"])\n",
    "campaign_df[\"from_date\"] = pd.to_datetime(campaign_df[\"from_date\"])\n",
    "campaign_df[\"duration\"] = (campaign_df[\"to_date\"] - campaign_df[\"from_date\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df[\"id\"] = event_df[\"campaign_id\"].astype(str) + \"-\" + event_df[\"uid\"] + \"-\" + event_df[\"timestamp\"].astype(str)\n",
    "event_df = event_df.groupby(\"campaign_id\")[\"id\"].agg([\"count\", \"nunique\"]).reset_index()\n",
    "event_df = event_df.rename(columns={\"count\": \"impression\", \"nunique\": \"reach\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df = order_df.merge(\n",
    "    campaign_df[[\"campaign_id\", \"discount\"]],\n",
    "    how=\"left\",\n",
    "    on=\"campaign_id\"\n",
    ").fillna(0)\n",
    "order_df[\"total\"] = (order_df[\"subtotal\"] - order_df[\"discount\"]).apply(abs)\n",
    "order_df = order_df.groupby(\"campaign_id\").agg(revenue=(\"total\", \"sum\")).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>discount</th>\n",
       "      <th>channel</th>\n",
       "      <th>duration</th>\n",
       "      <th>reach</th>\n",
       "      <th>impression</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mauris lacinia sapien quis libero.</td>\n",
       "      <td>208336</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>7874026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morbi odio odio, elementum eu, interdum eu, ti...</td>\n",
       "      <td>168279</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>8626189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suspendisse potenti.</td>\n",
       "      <td>121208</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>8535064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maecenas pulvinar lobortis est.</td>\n",
       "      <td>51187</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>13376904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aenean sit amet justo.</td>\n",
       "      <td>321561</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>5225609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ut tellus.</td>\n",
       "      <td>205002</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>7361549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In tempor, turpis nec euismod scelerisque, qua...</td>\n",
       "      <td>85811</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>11034949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cum sociis natoque penatibus et magnis dis par...</td>\n",
       "      <td>255076</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>5901392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In hac habitasse platea dictumst.</td>\n",
       "      <td>144461</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>9539272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Etiam pretium iaculis justo.</td>\n",
       "      <td>261198</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>10461180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pellentesque eget nunc.</td>\n",
       "      <td>143818</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>7421466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nam nulla.</td>\n",
       "      <td>296889</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>6256745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nulla neque libero, convallis eget, eleifend l...</td>\n",
       "      <td>436963</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>8241904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Integer aliquet, massa id lobortis convallis, ...</td>\n",
       "      <td>491535</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>5811043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ut at dolor quis odio consequat varius.</td>\n",
       "      <td>27049</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>16466946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Praesent blandit lacinia erat.</td>\n",
       "      <td>243964</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>12382359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pellentesque at nulla.</td>\n",
       "      <td>48304</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>8148174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lorem ipsum dolor sit amet, consectetuer adipi...</td>\n",
       "      <td>11779</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>11590018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Etiam justo.</td>\n",
       "      <td>46117</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>12082459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nullam porttitor lacus at turpis.</td>\n",
       "      <td>37028</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>11528663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Vestibulum sed magna at nunc commodo placerat.</td>\n",
       "      <td>338048</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>8694292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Suspendisse ornare consequat lectus.</td>\n",
       "      <td>279120</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>7578777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Integer aliquet, massa id lobortis convallis, ...</td>\n",
       "      <td>382680</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>7475152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Vestibulum ante ipsum primis in faucibus orci ...</td>\n",
       "      <td>172368</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>7076037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Nulla mollis molestie lorem.</td>\n",
       "      <td>163372</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>10589556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Morbi ut odio.</td>\n",
       "      <td>451997</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>2841472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Duis bibendum, felis sed interdum venenatis, t...</td>\n",
       "      <td>187487</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>9481408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>In eleifend quam a odio.</td>\n",
       "      <td>376038</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>7678665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Nam congue, risus semper porta volutpat, quam ...</td>\n",
       "      <td>285851</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>5373814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Nullam porttitor lacus at turpis.</td>\n",
       "      <td>248578</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>6207272.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       message  discount  \\\n",
       "campaign_id                                                                \n",
       "1                           Mauris lacinia sapien quis libero.    208336   \n",
       "2            Morbi odio odio, elementum eu, interdum eu, ti...    168279   \n",
       "3                                         Suspendisse potenti.    121208   \n",
       "4                              Maecenas pulvinar lobortis est.     51187   \n",
       "5                                       Aenean sit amet justo.    321561   \n",
       "6                                                   Ut tellus.    205002   \n",
       "7            In tempor, turpis nec euismod scelerisque, qua...     85811   \n",
       "8            Cum sociis natoque penatibus et magnis dis par...    255076   \n",
       "9                            In hac habitasse platea dictumst.    144461   \n",
       "10                                Etiam pretium iaculis justo.    261198   \n",
       "11                                     Pellentesque eget nunc.    143818   \n",
       "12                                                  Nam nulla.    296889   \n",
       "13           Nulla neque libero, convallis eget, eleifend l...    436963   \n",
       "14           Integer aliquet, massa id lobortis convallis, ...    491535   \n",
       "15                     Ut at dolor quis odio consequat varius.     27049   \n",
       "16                              Praesent blandit lacinia erat.    243964   \n",
       "17                                      Pellentesque at nulla.     48304   \n",
       "18           Lorem ipsum dolor sit amet, consectetuer adipi...     11779   \n",
       "19                                                Etiam justo.     46117   \n",
       "20                           Nullam porttitor lacus at turpis.     37028   \n",
       "21              Vestibulum sed magna at nunc commodo placerat.    338048   \n",
       "22                        Suspendisse ornare consequat lectus.    279120   \n",
       "23           Integer aliquet, massa id lobortis convallis, ...    382680   \n",
       "24           Vestibulum ante ipsum primis in faucibus orci ...    172368   \n",
       "25                                Nulla mollis molestie lorem.    163372   \n",
       "26                                              Morbi ut odio.    451997   \n",
       "27           Duis bibendum, felis sed interdum venenatis, t...    187487   \n",
       "28                                    In eleifend quam a odio.    376038   \n",
       "29           Nam congue, risus semper porta volutpat, quam ...    285851   \n",
       "30                           Nullam porttitor lacus at turpis.    248578   \n",
       "\n",
       "             channel  duration  reach  impression     revenue  \n",
       "campaign_id                                                    \n",
       "1                  2        13     36          36   7874026.0  \n",
       "2                  1        13     34          34   8626189.0  \n",
       "3                  1        18     31          31   8535064.0  \n",
       "4                  2         6     30          30  13376904.0  \n",
       "5                  1        13     34          34   5225609.0  \n",
       "6                  1        20     36          36   7361549.0  \n",
       "7                  1         9     34          34  11034949.0  \n",
       "8                  2        16     43          43   5901392.0  \n",
       "9                  1        30     31          31   9539272.0  \n",
       "10                 2        18     37          37  10461180.0  \n",
       "11                 2         9     43          43   7421466.0  \n",
       "12                 1         7     37          37   6256745.0  \n",
       "13                 2        10     25          25   8241904.0  \n",
       "14                 2        26     37          37   5811043.0  \n",
       "15                 3        30     31          31  16466946.0  \n",
       "16                 3        30     22          22  12382359.0  \n",
       "17                 1        15     35          35   8148174.0  \n",
       "18                 1        27     33          33  11590018.0  \n",
       "19                 3        24     37          37  12082459.0  \n",
       "20                 3        18     27          27  11528663.0  \n",
       "21                 3         8     30          30   8694292.0  \n",
       "22                 3         3     45          45   7578777.0  \n",
       "23                 3        19     34          34   7475152.0  \n",
       "24                 1         7     30          30   7076037.0  \n",
       "25                 2         8     31          31  10589556.0  \n",
       "26                 2        30     35          35   2841472.0  \n",
       "27                 2        26     40          40   9481408.0  \n",
       "28                 1        18     33          33   7678665.0  \n",
       "29                 3        10     22          22   5373814.0  \n",
       "30                 1        13     27          27   6207272.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = campaign_df.merge(\n",
    "    event_df,\n",
    "    \"left\",\n",
    "    \"campaign_id\"\n",
    ").merge(\n",
    "    order_df,\n",
    "    \"left\",\n",
    "    on=\"campaign_id\"\n",
    ")\n",
    "df = df[[\"campaign_id\", 'message', 'discount', 'channel', 'duration', 'reach', 'impression', 'revenue']].set_index(\"campaign_id\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caohu\\miniconda3\\envs\\internship\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 29482123526144.0000 - val_loss: 33173197029376.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 29221107793920.0000 - val_loss: 33173194932224.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 28924289482752.0000 - val_loss: 33173194932224.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 24450267348992.0000 - val_loss: 33173194932224.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 24649492594688.0000 - val_loss: 33173192835072.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 24449510277120.0000 - val_loss: 33173188640768.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 24880573579264.0000 - val_loss: 33173188640768.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 30534254198784.0000 - val_loss: 33173186543616.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 28334836678656.0000 - val_loss: 33173186543616.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 29445618401280.0000 - val_loss: 33173184446464.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 25633518256128.0000 - val_loss: 33173184446464.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 27918048690176.0000 - val_loss: 33173184446464.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 23597827489792.0000 - val_loss: 33173184446464.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 26215624736768.0000 - val_loss: 33173178155008.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 29048933711872.0000 - val_loss: 33173178155008.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 28756760592384.0000 - val_loss: 33173169766400.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 27153655660544.0000 - val_loss: 33173169766400.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 26217963061248.0000 - val_loss: 33173163474944.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 24020426686464.0000 - val_loss: 33173161377792.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 26619934670848.0000 - val_loss: 33173159280640.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 25745407606784.0000 - val_loss: 33173150892032.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 27644879962112.0000 - val_loss: 33173144600576.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 22529024458752.0000 - val_loss: 33173138309120.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 25306983301120.0000 - val_loss: 33173129920512.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 26191838838784.0000 - val_loss: 33173125726208.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 26002281463808.0000 - val_loss: 33173113143296.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 26516528300032.0000 - val_loss: 33173104754688.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 29367375757312.0000 - val_loss: 33173092171776.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 24866879176704.0000 - val_loss: 33173079588864.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 26856975761408.0000 - val_loss: 33173067005952.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 25596128133120.0000 - val_loss: 33173052325888.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 28532268859392.0000 - val_loss: 33173035548672.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 26384378363904.0000 - val_loss: 33173016674304.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 25120991084544.0000 - val_loss: 33172995702784.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 25767444480000.0000 - val_loss: 33172970536960.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 29086401429504.0000 - val_loss: 33172949565440.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 26894604959744.0000 - val_loss: 33172918108160.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 27077436768256.0000 - val_loss: 33172892942336.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 24576597688320.0000 - val_loss: 33172861485056.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 25862032326656.0000 - val_loss: 33172827930624.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 28387506651136.0000 - val_loss: 33172785987584.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 26058099261440.0000 - val_loss: 33172744044544.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 24633315164160.0000 - val_loss: 33172700004352.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 26235644149760.0000 - val_loss: 33172655964160.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 25145802489856.0000 - val_loss: 33172601438208.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 29307514650624.0000 - val_loss: 33172546912256.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 25212028452864.0000 - val_loss: 33172490289152.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 24509839048704.0000 - val_loss: 33172425277440.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 29306182959104.0000 - val_loss: 33172358168576.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 27881998647296.0000 - val_loss: 33172280573952.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22b372ea9f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['message', 'discount', 'channel', 'duration']]\n",
    "y = df[['reach', 'impression', 'revenue']]\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=10)\n",
    "X_message = tfidf.fit_transform(X['message']).toarray()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_numerical = scaler.fit_transform(X[['discount', 'channel', 'duration']])\n",
    "\n",
    "X_processed = np.hstack([X_message, X_numerical])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/scaler.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('../model/simulator.keras')\n",
    "joblib.dump(tfidf, '../model/tfidf_vectorizer.pkl')\n",
    "joblib.dump(scaler, '../model/scaler.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
